{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02046e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A t-test and a z-test are both statistical tests used to compare means and assess differences between groups or within a group over time. However, they have different applications depending on the sample size and whether the population variance is known. Here's a breakdown of their differences and example scenarios where each test would be appropriate:\n",
    "\n",
    "# t-Test\n",
    "# Sample Size: Typically used when the sample size is small (n < 30).\n",
    "# Population Variance: Used when the population variance is unknown.\n",
    "# Distribution: Uses the t-distribution, which has thicker tails than the normal distribution, providing more conservative results when sample sizes are small.\n",
    "# Example Scenario for a t-Test:\n",
    "# Imagine you are a researcher studying the effects of a new drug on blood pressure. You have a small sample size of 20 patients. You want to compare the average blood pressure before and after the treatment to see if there is a significant difference. Since the sample size is small and you don't know the population variance, you would use a paired t-test for this scenario.\n",
    "\n",
    "# z-Test\n",
    "# Sample Size: Typically used when the sample size is large (n ≥ 30).\n",
    "# Population Variance: Used when the population variance is known or when the sample size is sufficiently large that the sample variance can approximate the population variance.\n",
    "# Distribution: Uses the standard normal distribution (z-distribution).\n",
    "# Example Scenario for a z-Test:\n",
    "# Imagine you are analyzing the results of a nationwide survey on average household income. You have a large sample size of 500 households, and from historical data, you know the population variance of household incomes. You want to test if the average household income has significantly changed from a known national average. Since you have a large sample size and know the population variance, a z-test would be appropriate here.\n",
    "\n",
    "# Key Differences\n",
    "# Sample Size: t-tests are preferred for smaller samples, while z-tests are used for larger samples.\n",
    "# Population Variance: t-tests are used when the population variance is unknown, whereas z-tests require the population variance to be known or approximated.\n",
    "# Distribution: t-tests use the t-distribution, which accounts for additional uncertainty in small samples; z-tests use the normal distribution.\n",
    "# Summary\n",
    "# t-Test: Small sample sizes, unknown population variance.\n",
    "# z-Test: Large sample sizes, known population variance.\n",
    "# By understanding these differences and the context of your data, you can select the appropriate test to make valid inferences from your statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52650c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-tailed and two-tailed tests are both types of hypothesis tests used in statistics to determine whether there is enough evidence to reject a null hypothesis. The key difference lies in the direction of the effect being tested.\n",
    "\n",
    "# One-Tailed Test\n",
    "# Definition: A one-tailed test assesses whether a parameter is either greater than or less than a certain value, but not both. It tests for a deviation in only one direction.\n",
    "# Hypotheses:\n",
    "# Right-tailed test:\n",
    "# Null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# ≤\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ≤μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is less than or equal to a specified value)\n",
    "# Alternative hypothesis (\n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# >\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ>μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is greater than the specified value)\n",
    "# Left-tailed test:\n",
    "# Null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# ≥\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ≥μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is greater than or equal to a specified value)\n",
    "# Alternative hypothesis (\n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# <\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ<μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is less than the specified value)\n",
    "# Critical Region: The rejection region is in one tail of the distribution (either the upper or lower tail).\n",
    "# Example Scenario for a One-Tailed Test:\n",
    "# Suppose a pharmaceutical company claims that their new drug increases the average response rate by more than 20%. A researcher wants to test if this claim is valid. They would set up a right-tailed test with:\n",
    "\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  : The mean response rate \n",
    "# ≤\n",
    "# 20\n",
    "# %\n",
    "# ≤20%\n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#  : The mean response rate \n",
    "# >\n",
    "# 20\n",
    "# %\n",
    "# >20%\n",
    "# Two-Tailed Test\n",
    "# Definition: A two-tailed test assesses whether a parameter is significantly different from a certain value, in either direction (greater than or less than).\n",
    "# Hypotheses:\n",
    "# Null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# =\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ=μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is equal to a specified value)\n",
    "# Alternative hypothesis (\n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#  ): \n",
    "# 𝜇\n",
    "# ≠\n",
    "# 𝜇\n",
    "# 0\n",
    "# μ\n",
    "# \n",
    "# =μ \n",
    "# 0\n",
    "# ​\n",
    "#   (the mean is not equal to the specified value)\n",
    "# Critical Region: The rejection regions are in both tails of the distribution (both the upper and lower tails).\n",
    "# Example Scenario for a Two-Tailed Test:\n",
    "# A quality control manager wants to test if a machine is producing parts with an average length different from the target length of 10 cm. They would set up a two-tailed test with:\n",
    "\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  : The mean length = 10 cm\n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#  : The mean length \n",
    "# ≠\n",
    "# 10\n",
    "# \n",
    "# =10 cm\n",
    "# Key Differences\n",
    "# Direction of the Test:\n",
    "\n",
    "# One-tailed test: Tests for an effect in one specific direction (greater than or less than).\n",
    "# Two-tailed test: Tests for an effect in both directions (different from a specific value).\n",
    "# Critical Region:\n",
    "\n",
    "# One-tailed test: The rejection region is in one tail of the distribution.\n",
    "# Two-tailed test: The rejection regions are in both tails of the distribution.\n",
    "# Hypotheses:\n",
    "\n",
    "# One-tailed test: \n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#   specifies a direction (either \n",
    "# >\n",
    "# > or \n",
    "# <\n",
    "# <).\n",
    "# Two-tailed test: \n",
    "# 𝐻\n",
    "# 𝑎\n",
    "# H \n",
    "# a\n",
    "# ​\n",
    "#   does not specify a direction, only that there is a difference (\n",
    "# ≠\n",
    "# \n",
    "# =).\n",
    "# p-Values:\n",
    "\n",
    "# One-tailed test: The p-value represents the probability of obtaining a test statistic as extreme as, or more extreme than, the observed value in one direction.\n",
    "# Two-tailed test: The p-value represents the probability of obtaining a test statistic as extreme as, or more extreme than, the observed value in either direction.\n",
    "# By understanding the nature of the effect you are testing, you can choose the appropriate test (one-tailed or two-tailed) to properly address your research question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2541e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type I Error\n",
    "# Definition: A Type I error occurs when the null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ) is true, but we incorrectly reject it. It is also known as a \"false positive\" or \"alpha error.\"\n",
    "# Probability: The probability of making a Type I error is denoted by \n",
    "# 𝛼\n",
    "# α, which is the significance level of the test (commonly set at 0.05, 0.01, etc.).\n",
    "# Example Scenario for a Type I Error:\n",
    "# Imagine a clinical trial testing a new medication for lowering blood pressure. The null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ) is that the medication has no effect (i.e., the mean blood pressure after taking the medication is the same as before). If the trial results lead researchers to reject \n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#   and conclude that the medication does lower blood pressure, but in reality, it does not (the true mean remains unchanged), a Type I error has occurred.\n",
    "\n",
    "# Type II Error\n",
    "# Definition: A Type II error occurs when the null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ) is false, but we fail to reject it. It is also known as a \"false negative\" or \"beta error.\"\n",
    "# Probability: The probability of making a Type II error is denoted by \n",
    "# 𝛽\n",
    "# β. The power of a test (1 - \n",
    "# 𝛽\n",
    "# β) is the probability of correctly rejecting a false null hypothesis.\n",
    "# Example Scenario for a Type II Error:\n",
    "# Suppose a company implements a new training program intended to improve employee productivity. The null hypothesis (\n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ) is that the training program has no effect on productivity. If the statistical test fails to show a significant increase in productivity (fails to reject \n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  ), but in reality, the program does improve productivity, a Type II error has occurred.\n",
    "\n",
    "# Key Differences and Considerations\n",
    "# Type I Error (False Positive):\n",
    "# Occurs when the null hypothesis is true but rejected.\n",
    "# The significance level (\n",
    "# 𝛼\n",
    "# α) determines the threshold for rejecting \n",
    "# 𝐻\n",
    "# 0\n",
    "# H \n",
    "# 0\n",
    "# ​\n",
    "#  .\n",
    "# Reducing \n",
    "# 𝛼\n",
    "# α decreases the likelihood of a Type I error but increases the likelihood of a Type II error.\n",
    "# Type II Error (False Negative):\n",
    "# Occurs when the null hypothesis is false but not rejected.\n",
    "# The probability of a Type II error (\n",
    "# 𝛽\n",
    "# β) is influenced by the sample size, effect size, and significance level.\n",
    "# Increasing the sample size or the effect size can reduce the likelihood of a Type II error.\n",
    "# Balancing Type I and Type II Errors\n",
    "# In hypothesis testing, researchers must balance the risks of Type I and Type II errors. Lowering the significance level (\n",
    "# 𝛼\n",
    "# α) reduces the risk of a Type I error but increases the risk of a Type II error, and vice versa. The choice of \n",
    "# 𝛼\n",
    "# α often depends on the context of the test and the consequences of each type of error.\n",
    "\n",
    "# Summary\n",
    "# Type I Error:\n",
    "# Incorrectly rejecting a true null hypothesis.\n",
    "# Example: Concluding a medication works when it doesn't.\n",
    "# Type II Error:\n",
    "# Failing to reject a false null hypothesis.\n",
    "# Example: Concluding a training program doesn't work when it does.\n",
    "# By carefully considering the implications of both types of errors, researchers can design their studies to minimize these risks and make more accurate inferences from their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a973b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9076c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes's theorem is a fundamental concept in probability \n",
    "# theory and statistics, providing a way to update the probability of a\n",
    "# hypothesis based on new evidence. It relates the conditional and \n",
    "# marginal probabilities of random events and is particularly useful for \n",
    "# revising existing predictions or beliefs in light of new data.\n",
    "\n",
    "# Bayes's Theorem Formula\n",
    "# Bayes's theorem states:\n",
    "# 𝑃(𝐴∣𝐵)\n",
    "# =𝑃(𝐵∣𝐴)\n",
    "# ⋅\n",
    "# 𝑃(𝐴)\n",
    "# 𝑃(𝐵)\n",
    "# P(A∣B)= \n",
    "# P(B)\n",
    "# P(B∣A)⋅P(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  confidence interval (CI) is a range of values, derived from sample statistics, that is likely to contain the population parameter of interest with a specified level of confidence. It provides an estimate of the uncertainty around the sample statistic and is used to infer the population parameter.\n",
    "\n",
    "# Key Concepts\n",
    "# Confidence Level: The probability that the confidence interval contains the true population parameter. Common confidence levels are 90%, 95%, and 99%.\n",
    "# Margin of Error: The range above and below the sample statistic that is expected to contain the population parameter.\n",
    "# Calculating a Confidence Interval\n",
    "# The steps to calculate a confidence interval depend on whether you are dealing with means or proportions and whether the population standard deviation is known. Here, we will focus on the confidence interval for a population mean when the population standard deviation is unknown, using the t-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe186989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Despite the high sensitivity and specificity of the test, \n",
    "# the probability of having the disease after a positive test\n",
    "# result is relatively low due to the rarity of the disease. \n",
    "# This example illustrates \n",
    "# how Bayes' Theorem combines prior probability and the likelihood of the new evidence \n",
    "# to update the probability of an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58afc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the 95% confidence interval for a sample of data with a known mean and standard deviation, we can use the following steps. Let's assume we have a sufficiently large sample size (n ≥ 30), which allows us to use the z-distribution.\n",
    "\n",
    "# Given:\n",
    "# Sample mean (\n",
    "# 𝑥\n",
    "# ˉ\n",
    "# x\n",
    "# ˉ\n",
    "#  ) = 50\n",
    "# Sample standard deviation (s) = 5\n",
    "# Sample size (n) = Assume a large sample, n = 100 for this example\n",
    "# Confidence level = 95%\n",
    "# Steps to Calculate the Confidence Interval:\n",
    "# Determine the z-value for the 95% confidence level.\n",
    "\n",
    "# The z-value for a 95% confidence level is approximately 1.96 (This value comes from the standard normal distribution table corresponding to 95% confidence).\n",
    "# Calculate the standard error (SE):\n",
    "\n",
    "# 𝑆\n",
    "# 𝐸\n",
    "# =\n",
    "# 𝑠\n",
    "# 𝑛\n",
    "# =\n",
    "# 5\n",
    "# 100\n",
    "# =\n",
    "# 5\n",
    "# 10\n",
    "# =\n",
    "# 0.5\n",
    "# SE= \n",
    "# n\n",
    "# ​\n",
    " \n",
    "# s\n",
    "# ​\n",
    "#  = \n",
    "# 100\n",
    "# ​\n",
    " \n",
    "# 5\n",
    "# ​\n",
    "#  = \n",
    "# 10\n",
    "# 5\n",
    "# ​\n",
    "#  =0.5\n",
    "# Calculate the margin of error (ME):\n",
    "\n",
    "# 𝑀\n",
    "# 𝐸\n",
    "# =\n",
    "# 𝑧\n",
    "# ×\n",
    "# 𝑆\n",
    "# 𝐸\n",
    "# =\n",
    "# 1.96\n",
    "# ×\n",
    "# 0.5\n",
    "# =\n",
    "# 0.98\n",
    "# ME=z×SE=1.96×0.5=0.98\n",
    "# Determine the confidence interval:\n",
    "\n",
    "# Lower limit: \n",
    "# 𝑥\n",
    "# ˉ\n",
    "# −\n",
    "# 𝑀\n",
    "# 𝐸\n",
    "# =\n",
    "# 50\n",
    "# −\n",
    "# 0.98\n",
    "# =\n",
    "# 49.02\n",
    "# x\n",
    "# ˉ\n",
    "#  −ME=50−0.98=49.02\n",
    "# Upper limit: \n",
    "# 𝑥\n",
    "# ˉ\n",
    "# +\n",
    "# 𝑀\n",
    "# 𝐸\n",
    "# =\n",
    "# 50\n",
    "# +\n",
    "# 0.98\n",
    "# =\n",
    "# 50.98\n",
    "# x\n",
    "# ˉ\n",
    "#  +ME=50+0.98=50.98\n",
    "# Confidence Interval:\n",
    "# The 95% confidence interval for the population mean is (49.02, 50.98).\n",
    "\n",
    "# Interpretation:\n",
    "# We are 95% confident that the true population mean lies between 49.02 and 50.98. This means that if we were to take many samples and construct a confidence interval from each sample, approximately 95% of those intervals would contain the true population mean. This confidence interval gives us a range within which we believe the true mean of the population lies, based on our sample data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The margin of error (ME) in a confidence interval is the range of values above \n",
    "# and below the sample statistic that is expected to contain the population\n",
    "# parameter with a specified level of confidence. It represents the maximum \n",
    "# expected difference between the observed sample statistic and the true population parameter.\n",
    "# With the smaller sample size (\n",
    "# 𝑛\n",
    "# =\n",
    "# 25\n",
    "# n=25), the margin of error is 3.92, resulting in a wider confidence interval of (171.08, 178.92). When the sample size is increased \n",
    "# to 100, the margin of error decreases to 1.96, resulting in a narrower confidence interval of (173.04, 176.96). This illustrates that a larger sample size results in a smaller margin of error, providing a more precise estimate of the population parameter.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
